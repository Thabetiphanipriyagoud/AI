{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOPjp0ec4Rpb7SM3t4VJJCx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thabetiphanipriyagoud/AI/blob/main/Untitled12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "Ow_j1CWlf2GT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_Vzl0wGfuSN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from transformers import TFBertModel\n",
        "import transformers\n",
        "\n",
        "tf.config.experimental_run_functions_eagerly(False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YI7RBv9Jgown"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/NLP/train.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "eukqC7lbgoo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['discourse_type'].unique()"
      ],
      "metadata": {
        "id": "xnElkFjjgocr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bert_encode(texts, tokenizer, max_len=256):\n",
        "    input_ids = []\n",
        "    token_type_ids = []\n",
        "    attention_mask = []\n",
        "    \n",
        "    for text in texts:\n",
        "        token = tokenizer(text, max_length=256, truncation=True, padding='max_length',add_special_tokens=True)\n",
        "        input_ids.append(token['input_ids'])\n",
        "        token_type_ids.append(token['token_type_ids'])\n",
        "        attention_mask.append(token['attention_mask'])\n",
        "        \n",
        "    return np.array(input_ids), np.array(token_type_ids), np.array(attention_mask)"
      ],
      "metadata": {
        "id": "y0IFAkj9hl85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer"
      ],
      "metadata": {
        "id": "YWO_5GDMjI7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-cased')\n",
        "tokenizer.save_pretrained('.')"
      ],
      "metadata": {
        "id": "kpxxx6Tuhk5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding [SEP] for the Input Data\n",
        "df['inputs'] = df.discourse_type + '[SEP]' +df.discourse_text\n",
        "print(df)"
      ],
      "metadata": {
        "id": "4vi6KHovhj2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Label\n",
        "new_label = {\"discourse_effectiveness\": {\"Ineffective\": 0, \"Adequate\": 1, \"Effective\": 2}}\n",
        "df = df.replace(new_label)\n",
        "df = df.rename(columns = {\"discourse_effectiveness\": \"label\"})"
      ],
      "metadata": {
        "id": "ARgod2rlhuNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Mq4hKz4NhuAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(df['inputs'], df['label'], test_size=0.12, random_state=42)"
      ],
      "metadata": {
        "id": "SOTz5L9BiWrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = bert_encode(X_train.astype(str), tokenizer)\n",
        "X_valid = bert_encode(X_valid.astype(str), tokenizer)\n",
        "\n",
        "y_train = y_train.values\n",
        "y_valid = y_valid.values"
      ],
      "metadata": {
        "id": "UoQsreJyiWg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "train_dataset = (tf.data.Dataset.from_tensor_slices((X_train, y_train)).repeat().shuffle(2048).batch(16).prefetch(AUTO))\n",
        "valid_dataset = (tf.data.Dataset.from_tensor_slices((X_valid, y_valid)).batch(16).cache().prefetch(AUTO))"
      ],
      "metadata": {
        "id": "fSnvtZVUiWUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "id": "QDt5SZt2jo0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(bert_model, max_len=256):    \n",
        "    input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
        "    token_type_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"token_type_ids\")\n",
        "    attention_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
        "\n",
        "    sequence_output = bert_model.bert(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)[0]\n",
        "    clf_output = sequence_output[:, 0, :]\n",
        "    clf_output = Dropout(.1)(clf_output)\n",
        "    out = Dense(3, activation='softmax')(clf_output)\n",
        "    \n",
        "    model = Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=out)\n",
        "    model.compile(Adam(lr=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "DUq5VIP6jow0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "try:\n",
        "  resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  tf.config.experimental_connect_to_cluster(resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "  print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "except ValueError:\n",
        "  strategy = tf.distribute.get_strategy()"
      ],
      "metadata": {
        "id": "MYe_AdGC6hcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    transformer_layer = (TFBertModel.from_pretrained('bert-base-cased'))\n",
        "    model = build_model(transformer_layer, max_len=256)\n",
        "    \n",
        "    save_best = tf.keras.callbacks.ModelCheckpoint(\"Model.h5\", monitor='val_accuracy',save_best_only=True, verbose=1)\n",
        "    \n",
        "    model.summary()\n",
        "    print('\\n\\nModel Training..........................................\\n')\n",
        "    model.fit(train_dataset,steps_per_epoch=3, validation_data=valid_dataset, epochs=2, callbacks=[save_best])"
      ],
      "metadata": {
        "id": "Ne6nCqsJjotj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('./Model.h5')"
      ],
      "metadata": {
        "id": "lsgxjcpdjoq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv(\"/content/drive/MyDrive/NLP/test.csv\")\n",
        "test['text'] = test.discourse_type + '[SEP]' +test.discourse_text\n",
        "test.head()"
      ],
      "metadata": {
        "id": "k3YPkg1RjonT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_text = bert_encode(test.text.astype(str), tokenizer)"
      ],
      "metadata": {
        "id": "Og9q6kb0joj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub = pd.read_csv(\"/content/drive/MyDrive/NLP/sample_submission.csv\")\n",
        "sub.head()"
      ],
      "metadata": {
        "id": "qyvH07aGjobt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(test_text, verbose=1)\n",
        "preds"
      ],
      "metadata": {
        "id": "imsevIHFyija"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub['Ineffective'] = preds[:,0]\n",
        "sub['Adequate'] = preds[:,1]\n",
        "sub['Effective'] = preds[:,2]\n",
        "sub"
      ],
      "metadata": {
        "id": "zFB6mxdzytud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub.to_csv(\"submission.csv\", index=False)"
      ],
      "metadata": {
        "id": "CUxm3CODytqj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}